{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "603d97ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6047603e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U langchain langchain-google-genai google-generativeai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c2a5c58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyDjZOb4UWzcAZPfSHV_B9bor9pH20PcmcE\"\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"models/gemini-1.5-flash\",  # ✅ Working model\n",
    "    temperature=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fa4aad0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain, SequentialChain\n",
    "from langchain_core.callbacks import CallbackManager, StdOutCallbackHandler\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f6af5925",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_json = \"\"\"\n",
    "{\n",
    "  \"1\": {\n",
    "    \"mcq\": \"multiple choice question\",\n",
    "    \"options\": {\n",
    "      \"a\": \"choice here\",\n",
    "      \"b\": \"choice here\",\n",
    "      \"c\": \"choice here\",\n",
    "      \"d\": \"choice here\"\n",
    "    },\n",
    "    \"correct\": \"correct answer\"\n",
    "  },\n",
    "  \"2\": {\n",
    "    \"mcq\": \"multiple choice question\",\n",
    "    \"options\": {\n",
    "      \"a\": \"choice here\",\n",
    "      \"b\": \"choice here\",\n",
    "      \"c\": \"choice here\",\n",
    "      \"d\": \"choice here\"\n",
    "    },\n",
    "    \"correct\": \"correct answer\"\n",
    "  }\n",
    "}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a07d1aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TEMPLATE = \"\"\"\n",
    "Text:\n",
    "{text}\n",
    "\n",
    "You are an expert MCQ maker. Using ONLY the information in the text above,\n",
    "generate **{number} unique multiple choice questions** suitable for {subject}\n",
    "students. Use a {tone} tone.\n",
    "\n",
    "Return your answer **exactly** in the JSON format shown below (no extra keys,\n",
    "no markdown). Each question must have **four** options, one correct answer, and\n",
    "a one line explanation.\n",
    "\n",
    "### JSON_SCHEMA\n",
    "{response_json}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c8257827",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=TEMPLATE,\n",
    "    input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"response_json\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2a921bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_quiz = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    output_key=\"quiz\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c2a32da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE2 = \"\"\"\n",
    "You are an expert English grammarian and writer.  \n",
    "Given a Multiple Choice Quiz for {subject} students:\n",
    "\n",
    "• Evaluate the complexity of each question and provide a complete analysis of the quiz (maximum 50 words for the complexity summary).  \n",
    "• If any question is not in line with the cognitive and analytical abilities of the students, update those questions and adjust the tone so it perfectly fits the students.\n",
    "\n",
    "Quiz_MCQs:\n",
    "{quiz}\n",
    "\n",
    "Check from an expert English writer of the above quiz:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1ea486b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_evaluation_prompt = PromptTemplate(\n",
    "    template=TEMPLATE2,\n",
    "    input_variables=[\"subject\", \"quiz\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2d74da7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_quiz = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=quiz_evaluation_prompt,\n",
    "    output_key=\"review\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ed966c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gene_eval_chain = SequentialChain(\n",
    "    chains=[generate_quiz, review_quiz],\n",
    "    input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"response_json\"],\n",
    "    output_variables=[\"quiz\",\"review\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0aed20a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"C:/Users/Yashraj Sharma/MCQInterview_Generator/data.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "52909fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path,\"r\")as file:\n",
    "    Text=file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "463b0032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\\\\n{\\\\n  \\\\\"1\\\\\": {\\\\n    \\\\\"mcq\\\\\": \\\\\"multiple choice question\\\\\",\\\\n    \\\\\"options\\\\\": {\\\\n      \\\\\"a\\\\\": \\\\\"choice here\\\\\",\\\\n      \\\\\"b\\\\\": \\\\\"choice here\\\\\",\\\\n      \\\\\"c\\\\\": \\\\\"choice here\\\\\",\\\\n      \\\\\"d\\\\\": \\\\\"choice here\\\\\"\\\\n    },\\\\n    \\\\\"correct\\\\\": \\\\\"correct answer\\\\\"\\\\n  },\\\\n  \\\\\"2\\\\\": {\\\\n    \\\\\"mcq\\\\\": \\\\\"multiple choice question\\\\\",\\\\n    \\\\\"options\\\\\": {\\\\n      \\\\\"a\\\\\": \\\\\"choice here\\\\\",\\\\n      \\\\\"b\\\\\": \\\\\"choice here\\\\\",\\\\n      \\\\\"c\\\\\": \\\\\"choice here\\\\\",\\\\n      \\\\\"d\\\\\": \\\\\"choice here\\\\\"\\\\n    },\\\\n    \\\\\"correct\\\\\": \\\\\"correct answer\\\\\"\\\\n  }\\\\n}\\\\n\"'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.dumps(response_json)#python dic to json string"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcq_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
